{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Various tests of normality\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from statsmodels.stats.diagnostic import lilliefors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the county election data, and the county health rankings data for 2016.\n",
    "# Store in a variabled called \"df\"\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/thomaspingel/geodata/master/election/county_election_data_2000-2016.csv'\n",
    "election_df = pd.read_csv(url,dtype={'FIPS':str})\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/thomaspingel/geodata/master/county_health_rankings/chr_2016.csv'\n",
    "health_df = pd.read_csv(url,dtype={'FIPS':str})\n",
    "\n",
    "df = health_df.merge(election_df,how='left',on='FIPS')\n",
    "\n",
    "# Column names often have spaces.  Use this command to replace spaces with underscores\n",
    "# df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Exploring Transformations of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformations are a useful way to take data that is skewed and de-skew it so that it performs better in a regression model (i.e., is more predictive).**\n",
    "\n",
    "_Log transforms_ are a useful way to transform data when\n",
    "* data values are positive AND\n",
    "* data values are skewed right (i.e., clustered heavily to the left)\n",
    "\n",
    "If data seem clustered left BUT they are not positive, you can add a value to recenter the distribution\n",
    "\n",
    "_Arithmetic and power transforms are also useful._\n",
    "One can also raise the values to a power, either greater than one (e.g., the square or second power) or between zero and 1 (e.g., square root or .5 power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Instructions</u>: Using the codeblock below, explore ten different likely contributors to the prediction model to see if they likely require transformation before inclusion.  Use the histograms to visually diagnose how normal they appear.  While nothing will be completely normal, does it have a general \"bell\" shape, or is it bunched up at one end or the other.  If it's bunched up toward the left, that's a \"right skew\" as it has a longer right \"tail\".  If you need to review concepts of skew, please see the [statisticshowto.com page and video on skew](https://www.statisticshowto.com/probability-and-statistics/skewed-distribution/).  Indicators of skew should use weak/moderate/strong left/right skew.\n",
    "\n",
    "Paste your best transform code (everything to the right of the equals sign) into the markdown table.  Please order variables alphabetically (manually).  Two of these have been done for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Untransformed skew | Transform | \n",
    "| ----------- | ---- | ----------- |\n",
    "| Demographics - Population   | Strong Right | np.log(x) |\n",
    "| gop_minus_dem_prc_2012 | Weak Left | (x + 100) ** 1.4 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this line to choose a variable from the list above\n",
    "x = df['Demographics - Population'].dropna()\n",
    "\n",
    "# And modify this line to the right of the equal sign to make a transformation.\n",
    "# Options include a log transform, and adding a value and/or raising to a positive exponent.\n",
    "# Example: xt = np.log(x)\n",
    "# Example: xt = (x + 100) ** 2.5\n",
    "xt =  np.log(x)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "_ = plt.hist(x,bins=25)\n",
    "plt.subplot(122)\n",
    "_ = plt.hist(xt,bins=25)\n",
    "\n",
    "# Statistical tests of normality\n",
    "# If the P-Value is less than .05, the data are not normal\n",
    "# Graduate students should pay attention to these values and understand their import\n",
    "print('Untransformed: ',shapiro(x))\n",
    "print('Transformed:',shapiro(xt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Test variables one at a time for R<sup>2</sup> value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Instructions</u> - Using the variables and transformation methods you've aggregated above, run each variable twice - first untransformed, then transformed in the way you specified above - and put the results in this table, sorted (manually) by R2 or Transformed R2 score, whichever is higher (use the highest score as that line's score).  Include a VERY short statement indicating the logic of inclusion in the model.  Add a markdown paragraph below this table, and explain what variables are worth including in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | R<sup>2</sup> | R<sup>2</sup><sub>trans</sub> | Rationale |\n",
    "| ----------- | :---- | :-----| ----------:| \n",
    "| gop_minus_dem_prc_2012 | 0.891 | 0.870 | States are likely to vote like they did the last time |\n",
    "| Demographics - Population   | 0.123 | 0.255 | Larger states are more likely to vote Democrat |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame()\n",
    "\n",
    "_df['y'] = df['gop_minus_dem_prc_2016']\n",
    "\n",
    "# Edit this value, first as just the column, and again using the transformation you picked above\n",
    "_df['x'] = np.log(df['Demographics - Population'])\n",
    "\n",
    "_df = _df.dropna(how='any')\n",
    "\n",
    "# Then run the regression\n",
    "results = smf.ols(formula='y ~ x',data=_df).fit()\n",
    "\n",
    "# Print the report\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Multiple Regression Round 1 - Investigate interaction effects\n",
    "\n",
    "<u>Instructions</u> - Choose 3 or 4 of the highest scoring variables (some discretion is OK here), and include them in a model with with full interaction effects.  Express the models as either untransformed values or transformed values if you think the transformation significantly improves the explanatory power.  Review the output, and use the by variable/interaction report to fill in the table for all interactions tested.  If the value is under p < .05, the interaction is statistically significant:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variables | Result\n",
    "| --------- | -------\n",
    "| x0 | Example: Statistically Significant\n",
    "| x1 | Example: Not Statistically Significant\n",
    "| x2 | ???\n",
    "| x0 and x1 | ???\n",
    "| x0 and x2 | ???\n",
    "| x1 and x2 | ???\n",
    "| x0 and x1 and x2 | ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame()\n",
    "\n",
    "_df['y'] = df['gop_minus_dem_prc_2016']\n",
    "\n",
    "_df['x0'] = df['gop_minus_dem_prc_2012']\n",
    "_df['x1'] = df['Demographics - Population']\n",
    "_df['x2'] = df['Sexually transmitted infections - Chlamydia Rate']\n",
    "\n",
    "_df = _df.dropna(how='any')\n",
    "\n",
    "# Then run the regression\n",
    "results = smf.ols(formula='y ~ x0 * x1 * x2',data=_df).fit()\n",
    "\n",
    "# Print the report\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Multiple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Instructions</u> - Use all of the above information to construct a final model with individual and interaction terms, as needed and dictated by an analysis of the resulting p-values.  You'll need to edit your model and formula, rerun several times adding and removing terms as dictated by the p-values, and then step though the crosstabulation code below.  No editing of any codebock other than the one directly beneath these instructions should be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame()\n",
    "\n",
    "_df['y'] = df['gop_minus_dem_prc_2016']\n",
    "\n",
    "_df['x0'] = df['variable1']\n",
    "_df['x1'] = df['variable2']\n",
    "_df['x2'] = df['variable3']\n",
    "\n",
    "_df = _df.dropna(how='any')\n",
    "\n",
    "# Then run the regression\n",
    "results = smf.ols(formula='y ~ x0 + x1 + x2 + x0:x1 + x1:x2 + x0:x1:x2',data=_df).fit()\n",
    "\n",
    "# Print the report\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constuct a dataframe of the confusion matrix, calculated with pandas.crosstab\n",
    "# Here, only binary options are considered (R wins or D wins, not percent victory)\n",
    "\n",
    "output_df = pd.DataFrame({'true':df['gop_minus_dem_prc_2016']>0,'predicted':results.fittedvalues>0})\n",
    "output_df['true'] = output_df['true'].map({True:'R',False:'D'})\n",
    "output_df['predicted'] = output_df['predicted'].map({True:'R',False:'D'})\n",
    "cross = pd.crosstab(output_df.true,output_df.predicted)\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the normalized values (percents)\n",
    "\n",
    "cross = pd.crosstab(output_df.true,output_df.predicted,normalize=True)\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How accurate was the total model at predicting R/D victory\n",
    "\n",
    "100 * (cross.values[0,0] + cross.values[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - Write up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Instructions</u> - Write a short paragraph in a markdown cell explaining what you learned about regression, and about \n",
    "predicting 2016 election results.  Name 5 more variables not included in these datasets that you think might be helpful in predicting the results.  These variables should be operationally valid - meaning, one could easily imagine that such data exist.  When complete, render this notebook as a PDF via notebook-as-pdf, by exporting (File -> Download As -> PDF via HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
